{
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `gpt_researcher.memory.embeddings`/Memory#get_embeddings().": "Returns the embeddings stored in the object.\n---\nAccesses the private attribute _embeddings of the object and returns its value.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `gpt_researcher.context.retriever`/SearchAPIRetriever#": "Retrieves relevant documents from a list of pages based on a given query.\n---\nCreates a list of Document objects from the pages attribute, each Document containing the raw content of a page and metadata including the page's title and URL.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `backend.utils`/write_to_file().": "Writes provided text to a specified file asynchronously.\n---\nEncodes the input text to UTF-8, replacing any problematic characters. Uses aiofiles to open the specified file in write mode with UTF-8 encoding, then writes the encoded text to the file.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `gpt_researcher.utils.websocket_manager`/WebSocketManager#disconnect().": "Manages disconnection of a websocket from active connections.\n---\nChecks if the websocket is in active connections, removes it if present, cancels its sender task, puts a None message in its queue, and finally deletes its sender task and message queue.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `gpt_researcher.context.compression`/ContextCompressor#_pretty_print_docs().": "Formats and prints document metadata and content for a specified number of documents.\n---\nGenerates a string representation of the 'source', 'title', and 'page_content' of each document in the 'docs' list, up to a maximum of 'top_n' documents, and joins them with newline characters.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `gpt_researcher.master.agent`/GPTResearcher#get_new_urls().": "Extracts and returns new URLs from a given set that have not been visited before.\n---\nIterates over the input URL set, checks each URL against a set of visited URLs, and if the URL is not in the visited set, it is added to the visited set and appended to the new_urls list. The function also sends a log message to a websocket for each new URL found.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `gpt_researcher.retrievers.tavily_search.tavily_search`/TavilySearch#search().": "Executes a search query and returns a maximum of 7 results, with a fallback to a different search API in case of overload.\n---\nAttempts to execute a search query using the client's search method with advanced search depth and a specified maximum number of results. If an exception occurs (likely due to overload), it falls back to using the DDGS search API. The results are returned as a list of dictionaries, each containing the URL and content of the search result.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `gpt_researcher.utils.websocket_manager`/WebSocketManager#start_sender().": "Manages the sending of messages from a queue to active websocket connections.\n---\nRetrieves a message queue associated with a given websocket. If the queue exists, it enters a loop where it continuously gets messages from the queue and sends them to the websocket, provided the websocket is still active. If the websocket is inactive or an error occurs during message sending, the loop breaks.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `gpt_researcher.context.compression`/ContextCompressor#_get_contextual_retriever().": "Retrieves relevant documents from a list of pages based on a given query.\n---\nCreates a DocumentCompressorPipeline with a RecursiveCharacterTextSplitter and an EmbeddingsFilter. This pipeline is used in a SearchAPIRetriever, which is then used in a ContextualCompressionRetriever. The ContextualCompressionRetriever is returned.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `backend.utils`/write_md_to_pdf().": "Converts Markdown text to a PDF file and returns the encoded file path. The function is asynchronous and handles any exceptions that may occur during the conversion process.\n---\nGenerates a unique task ID and uses it to create a file path. The input text is written to a Markdown file at this path. The Markdown file is then converted to a PDF using the md2pdf function. If an error occurs during conversion, it is caught and printed, and an empty string is returned. If the conversion is successful, the file path of the PDF is encoded and returned.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `gpt_researcher.utils.websocket_manager`/WebSocketManager#connect().": "Manages the connection of a websocket and the initiation of a message sending task for it.\n---\nAccepts a websocket connection, adds it to the list of active connections, creates a new message queue for it, and starts a new asynchronous task to send messages from the queue to the websocket.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `gpt_researcher.context.compression`/ContextCompressor#get_context().": "Retrieves relevant documents based on a query and formats the document metadata and content for display.\n---\nCreates a DocumentCompressorPipeline with a RecursiveCharacterTextSplitter and an EmbeddingsFilter for use in a SearchAPIRetriever and a ContextualCompressionRetriever. Retrieves relevant documents using the ContextualCompressionRetriever and formats the 'source', 'title', and 'page_content' of each document for display, up to a specified maximum number of documents.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `gpt_researcher.master.agent`/GPTResearcher#scrape_sites_by_query().": "Executes a search query, retrieves a maximum of 7 results, and extracts new URLs that have not been visited before. The results are then scraped for relevant information.\n---\nThe function first attempts to execute a search query using the client's search method with advanced search depth and a specified maximum number of results. If an exception occurs, it falls back to using the DDGS search API. The results are returned as a list of dictionaries. It then iterates over the input URL set, checks each URL against a set of visited URLs, and if the URL is not in the visited set, it is added to the visited set and appended to the new_urls list. The function also sends a log message to a websocket for each new URL found. Finally, the new URLs are scraped for relevant information.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `gpt_researcher.master.agent`/GPTResearcher#get_similar_content_by_query().": "Retrieves and formats relevant documents based on a given query, using stored embeddings and a context compressor.\n---\nAccesses stored embeddings and uses them to create a ContextCompressor. This compressor is then used to retrieve relevant documents using a DocumentCompressorPipeline with a RecursiveCharacterTextSplitter and an EmbeddingsFilter. The 'source', 'title', and 'page_content' of each document are formatted for display, up to a maximum of 8 results.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `gpt_researcher.master.agent`/GPTResearcher#get_context_by_search().": "Generates context for a research task by executing search queries, retrieving and scraping results, and formatting relevant documents for display. \n---\nThe function generates sub-queries, logs them to a websocket, and then runs each sub-query. It attempts to execute a search query using the client's search method, and if an exception occurs, it falls back to using the DDGS search API. The results are scraped for relevant information. The function then retrieves and formats relevant documents using stored embeddings and a context compressor. The 'source', 'title', and 'page_content' of each document are formatted for display and logged to a websocket. The formatted content is appended to the context list, which is returned at the end.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `gpt_researcher.master.agent`/GPTResearcher#get_context_by_urls().": "Extracts unvisited URLs from a given set and conducts research based on these URLs. Retrieves and formats relevant documents based on a given query using stored embeddings and a context compressor.\n---\nIterates over the input URL set, checks each URL against a set of visited URLs, and if the URL is not in the visited set, it is added to the visited set and appended to the new_urls list. Sends a log message to a websocket for each new URL found. Accesses stored embeddings and uses them to create a ContextCompressor. This compressor is then used to retrieve relevant documents using a DocumentCompressorPipeline with a RecursiveCharacterTextSplitter and an EmbeddingsFilter. The 'source', 'title', and 'page_content' of each document are formatted for display, up to a maximum of 8 results.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `gpt_researcher.master.agent`/GPTResearcher#run().": "Conducts research based on a given query, either by extracting unvisited URLs from a given set or by executing search queries. The relevant documents are retrieved and formatted for display. A research report is then generated based on the retrieved context.\n---\nThe function first chooses an agent based on the query and configuration. If source URLs are provided, it iterates over them, checks each URL against a set of visited URLs, and retrieves and formats relevant documents using stored embeddings and a context compressor. If no source URLs are provided, it generates sub-queries, executes them, and retrieves and formats relevant documents in a similar manner. Finally, it generates a research report based on the retrieved context, the query, the agent role, the report type, and the configuration. The report is returned after a delay of 2 seconds.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `gpt_researcher.utils.websocket_manager`/run_agent().": "Executes a research task using a GPTResearcher agent, which retrieves and formats relevant documents based on a given query, and generates a research report. The total runtime is logged and sent via websocket.\n---\nInitializes a GPTResearcher with the given task, report type, and optional source URLs and configuration. The researcher runs, retrieving and formatting documents either from the source URLs or generated sub-queries. A research report is generated and returned. The total runtime is calculated and sent as a JSON message via the provided websocket.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `gpt_researcher.utils.websocket_manager`/WebSocketManager#start_streaming().": "Executes a research task using a GPTResearcher agent, streaming the generated research report and total runtime via a websocket.\n---\nInitializes a GPTResearcher with a given task and report type, retrieves and formats documents, generates a research report, calculates total runtime, and sends it as a JSON message via the provided websocket.",
    "scip-python python . 474f997a5a2f9a3908764c154e95c86ac994a8e2 `backend.server`/websocket_endpoint().": "Manages and maintains websocket connections, initiates message sending tasks, executes research tasks using a GPTResearcher agent, streams generated research reports and total runtime via websocket, and handles websocket disconnections. Additionally, it converts Markdown text to a PDF file and returns the encoded file path, handling any exceptions during the conversion process.\n---\nAccepts a websocket connection, adds it to the list of active connections, creates a new message queue for it, and starts a new asynchronous task to send messages from the queue to the websocket. It initializes a GPTResearcher with a given task and report type, retrieves and formats documents, generates a research report, calculates total runtime, and sends it as a JSON message via the provided websocket. It also generates a unique task ID and uses it to create a file path, writes the input text to a Markdown file at this path, converts the Markdown file to a PDF using the md2pdf function, and handles any errors during conversion. If the websocket disconnects, it checks if the websocket is in active connections, removes it if present, cancels its sender task, puts a None message in its queue, and finally deletes its sender task and message queue."
  }